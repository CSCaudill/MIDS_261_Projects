{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/**********************************************************************************************\n",
       "Known Mathjax Issue with Chrome - a rounding issue adds a border to the right of mathjax markup\n",
       "https://github.com/mathjax/MathJax/issues/1300\n",
       "A quick hack to fix this based on stackoverflow discussions: \n",
       "http://stackoverflow.com/questions/34277967/chrome-rendering-mathjax-equations-with-a-trailing-vertical-line\n",
       "**********************************************************************************************/\n",
       "\n",
       "$('.math>span').css(\"border-left-color\",\"transparent\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "/**********************************************************************************************\n",
    "Known Mathjax Issue with Chrome - a rounding issue adds a border to the right of mathjax markup\n",
    "https://github.com/mathjax/MathJax/issues/1300\n",
    "A quick hack to fix this based on stackoverflow discussions: \n",
    "http://stackoverflow.com/questions/34277967/chrome-rendering-mathjax-equations-with-a-trailing-vertical-line\n",
    "**********************************************************************************************/\n",
    "\n",
    "$('.math>span').css(\"border-left-color\",\"transparent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS - w261 Machine Learning At Scale\n",
    "__Course Lead:__ Dr James G. Shanahan (__email__ Jimi via  James.Shanahan _AT_ gmail.com)\n",
    "\n",
    "## Assignment - HW1\n",
    "\n",
    "\n",
    "---\n",
    "__Name:__  *Your Name Goes Here*   \n",
    "__Class:__ MIDS w261 (Section *Your Section Goes Here*, e.g., Fall 2016 Group 1)     \n",
    "__Email:__  *Your UC Berkeley Email Goes Here*@iSchool.Berkeley.edu   \n",
    "__StudentId__  123457    __End of StudentId__   \n",
    "__Week:__   1\n",
    "\n",
    "__NOTE__ please replace `1234567` with your student id above   \n",
    "__Due Time:__ HW is due the Tuesday of the following week by 8AM (West coast time). I.e., Tuesday,Jan 17, 2017 in the case of this homework. Please note a late submission may result in a ZERO grade for this homework.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents <a name=\"TOC\"></a> \n",
    "\n",
    "1.  [HW Intructions](#1)   \n",
    "2.  [HW References](#2)\n",
    "3.  [HW Problems](#3)   \n",
    "1.  [HW Introduction](#1)   \n",
    "2.  [HW References](#2)\n",
    "3.  [HW  Problems](#3)   \n",
    "    1.0.  [HW1.0](#1.0)   \n",
    "    1.0.  [HW1.1](#1.1)   \n",
    "    1.2.  [HW1.2](#1.2)   \n",
    "    1.3.  [HW1.3](#1.3)    \n",
    "    1.4.  [HW1.4](#1.4)    \n",
    "    1.5.  [HW1.5](#1.5)    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\">\n",
    "# 1 Instructions\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "MIDS UC Berkeley, Machine Learning at Scale\n",
    "DATSCIW261 ASSIGNMENT #1\n",
    "\n",
    "Version 2017-01-12 \n",
    "\n",
    "\n",
    "### IMPORTANT\n",
    "\n",
    "HW1 can be completed locally on your computer. You will not need any other python modules than the ones provided. For example, you should not have to import numpy.\n",
    "\n",
    "Homeworks will be graded using a combination of manual review and unit tests. Where applicable, please make sure to enter your solution between the comments:    \n",
    "`# START STUDENT CODE`   \n",
    "`# END STUDENT CODE`.    \n",
    "For questions that contain the above comments, do not modify anything else in the code block. \n",
    "\n",
    "Create a HW1 directory on your hard-drive, and place this notebook into it. Rename it to include your UCB student id. All files output by the code blocks should also reside at the root of your HW1 directory. It might look something like this:\n",
    "<pre>\n",
    "localhost:HW1 $ pwd\n",
    "/Users/johndoes/Documents/UCBerkeley/261/HW1\n",
    "\n",
    "localhost:HW1 $ tree\n",
    "    ├── MIDS-W261-HW-01-yourUCBid.ipynb\n",
    "    ├── alice_words.py\n",
    "    ├── alice_words.txt\n",
    "    ├── alicesTExtFilename.txt\n",
    "    ├── alicesTExtFilename.txt.output\n",
    "    ├── hw11.py\n",
    "    ├── hw111.py\n",
    "    ├── hw111.pyc\n",
    "    ├── mapper.py\n",
    "    ├── pWordCount.sh\n",
    "    ├── reducer.py\n",
    "    \n",
    "    0 directories, 11 files\n",
    "\n",
    "</pre>\n",
    "\n",
    "### === INSTRUCTIONS for SUBMISSIONS ===   \n",
    "Follow the instructions for submissions carefully.\n",
    "\n",
    "Click this link to enable you to create a github repo within the MIDS261 Classroom:  https://classroom.github.com/assignment-invitations/51317dde89d412134a749f035a0d59d3 , and follow the instructions to create a HW1 repo.\n",
    "\n",
    "Push the following to your HW1 github repo into the master branch:\n",
    "* PDF export of IPython Notebook.\n",
    "* The contents of your local HW1 directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\">\n",
    "# 2 Useful References\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "* See lecture 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\">\n",
    "# 3 HW Problems\n",
    "[Back to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.0  <a name=\"1.0\"></a>\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "### HW1.0.1.  Self-Introduction\n",
    "W1.0.0 Prepare your bio and include it in this HW submission. Please limit to 100 words. Count the words in your bio and print the length of your bio (in terms of words) in a separate cell.\n",
    "\n",
    "Fill in the following information [Optional]\n",
    "* Your Location \n",
    "* When did you start MIDS  and what is your target finish date\n",
    "* What you want to get out of w261?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW1.0.2. Big data\n",
    "Define big data. Provide an example of a big data problem in your domain of expertise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW1.0.3.  Bias Variance\n",
    "What is  bias-variance decomposition in the context machine learning? How is it used in machine learning? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW1.1 WordCount using a single thread  <a name=\"1.1\"></a>\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Write a program called alice_words.py that creates a text file named __alice_words.txt__ containing an alphabetical tab separated listing of all the words, and the number of times each occurs, in the text version of Alice’s Adventures in Wonderland. (You can obtain a free plain text version of the book, along with many others, from [here](http://www.gutenberg.org/cache/epub/11/pg11.txt) The first 10 lines of your output file should look something like this (the counts are not totally precise):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "a          690\n",
    "abide      2\n",
    "able       1\n",
    "about      102\n",
    "above      3\n",
    "absence    1\n",
    "absurd     2\n",
    "accept     1\n",
    "acceptance 1\n",
    "accepted   2\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/khamilton/Documents/UCBerkeley/261/HW1\r\n"
     ]
    }
   ],
   "source": [
    "# Make sure you are in HW1 directory\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  169k  100  169k    0     0   176k      0 --:--:-- --:--:-- --:--:--  176k\n"
     ]
    }
   ],
   "source": [
    "# !curl 'http://www.gutenberg.org/cache/epub/11/pg11.txt' -o alicesTExtFilename.txt\n",
    "# sometimes the above link produces junk characters. However, the direct link works as expected:\n",
    "!curl 'http://www.gutenberg.org/files/11/11-0.txt' -o alicesTExtFilename.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿Project Gutenberg’s Alice’s Adventures in Wonderland, by Lewis Carroll\r",
      "\r\n",
      "\r",
      "\r\n",
      "This eBook is for the use of anyone anywhere at no cost and with\r",
      "\r\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\r",
      "\r\n",
      "re-use it under the terms of the Project Gutenberg License included\r",
      "\r\n",
      "with this eBook or online at www.gutenberg.org\r",
      "\r\n",
      "\r",
      "\r\n",
      "\r",
      "\r\n",
      "Title: Alice’s Adventures in Wonderland\r",
      "\r\n",
      "\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "#display the first few lines\n",
    "!head alicesTExtFilename.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beck',\n",
       " 'global',\n",
       " 'risk',\n",
       " 'management',\n",
       " 'operations',\n",
       " 'congratulations',\n",
       " 'sally',\n",
       " 'kk',\n",
       " 'forwarded',\n",
       " 'by']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of a regular expression to detect words in a string. \n",
    "import re\n",
    "line = \"\"\" 0017.2000-01-17.beck\t0\t global risk management operations\t\" congratulations, sally!!!  kk  ----------------------forwarded by kathy kokas/corp/enron on 01/17/2000  08:08 pm---------------------------  from: rick causey 01/17/2000 06:04 pm  sent by: enron announcements  to: all enron worldwide  cc:  subject: global risk management operations  recognizing enron \u0001, s increasing worldwide presence in the wholesale energy  business and the need to insure outstanding internal controls for all of our  risk management activities, regardless of location, a global risk management  operations function has been created under the direction of sally w. beck,  vice president. in this role, sally will report to rick causey, executive  vice president and chief accounting officer.  sally \u0001, s responsibilities with regard to global risk management operations  will mirror those of other recently created enron global functions. in this  role, sally will work closely with all enron geographic regions and wholesale  companies to insure that each entity receives individualized regional support  while also focusing on the following global responsibilities:  1. enhance communication among risk management operations professionals.  2. assure the proliferation of best operational practices around the globe.  3. facilitate the allocation of human resources.  4. provide training for risk management operations personnel.  5. coordinate user requirements for shared operational systems.  6. oversee the creation of a global internal control audit plan for risk  management activities.  7. establish procedures for opening new risk management operations offices  and create key benchmarks for measuring on-going risk controls.  each regional operations team will continue its direct reporting relationship  within its business unit, and will collaborate with sally in the delivery of  these critical items. the houston-based risk management operations team under  sue frusco \u0001, s leadership, which currently supports risk management activities  for south america and australia, will also report directly to sally.  sally retains her role as vice president of energy operations for enron  north america, reporting to the ena office of the chairman. she has been in  her current role over energy operations since 1997, where she manages risk  consolidation and reporting, risk management administration, physical product  delivery, confirmations and cash management for ena \u0001, s physical commodity  trading, energy derivatives trading and financial products trading.  sally has been with enron since 1992, when she joined the company as a  manager in global credit. prior to joining enron, sally had four years  experience as a commercial banker and spent seven years as a registered  securities principal with a regional investment banking firm. she also owned  and managed a retail business for several years.  please join me in supporting sally in this additional coordination role for  global risk management operations.\"\"\"\n",
    "re.findall(r'[a-z]+', line.lower()) [0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries are a good way to keep track of word counts\n",
    "\n",
    "wordCounts={} \n",
    "\n",
    "### defaultdict are slightly more effectice way of doing word counting\n",
    " One way to do word counting but not best. A defaultdict is like a regular dictionary, except that when you try to look up a key it doesn’t contain, it first adds a value for it using a zero-argument function you provided\n",
    "when you created it. In order to use defaultdicts, you have to import them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 7)\n",
      "('accounting', 1)\n",
      "('activities', 3)\n",
      "('additional', 1)\n",
      "('administration', 1)\n",
      "('all', 3)\n",
      "('allocation', 1)\n",
      "('also', 3)\n",
      "('america', 2)\n",
      "('among', 1)\n"
     ]
    }
   ],
   "source": [
    "# Here is an example of wordcounting with a defaultdict (dictionary structure with a nice \n",
    "# default behaviours when a key does not exist in the dictionary\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "line = \"\"\" 0017.2000-01-17.beck\t0\t global risk management operations\t\" congratulations, sally!!!  kk  ----------------------forwarded by kathy kokas/corp/enron on 01/17/2000  08:08 pm---------------------------  from: rick causey 01/17/2000 06:04 pm  sent by: enron announcements  to: all enron worldwide  cc:  subject: global risk management operations  recognizing enron \u0001, s increasing worldwide presence in the wholesale energy  business and the need to insure outstanding internal controls for all of our  risk management activities, regardless of location, a global risk management  operations function has been created under the direction of sally w. beck,  vice president. in this role, sally will report to rick causey, executive  vice president and chief accounting officer.  sally \u0001, s responsibilities with regard to global risk management operations  will mirror those of other recently created enron global functions. in this  role, sally will work closely with all enron geographic regions and wholesale  companies to insure that each entity receives individualized regional support  while also focusing on the following global responsibilities:  1. enhance communication among risk management operations professionals.  2. assure the proliferation of best operational practices around the globe.  3. facilitate the allocation of human resources.  4. provide training for risk management operations personnel.  5. coordinate user requirements for shared operational systems.  6. oversee the creation of a global internal control audit plan for risk  management activities.  7. establish procedures for opening new risk management operations offices  and create key benchmarks for measuring on-going risk controls.  each regional operations team will continue its direct reporting relationship  within its business unit, and will collaborate with sally in the delivery of  these critical items. the houston-based risk management operations team under  sue frusco \u0001, s leadership, which currently supports risk management activities  for south america and australia, will also report directly to sally.  sally retains her role as vice president of energy operations for enron  north america, reporting to the ena office of the chairman. she has been in  her current role over energy operations since 1997, where she manages risk  consolidation and reporting, risk management administration, physical product  delivery, confirmations and cash management for ena \u0001, s physical commodity  trading, energy derivatives trading and financial products trading.  sally has been with enron since 1992, when she joined the company as a  manager in global credit. prior to joining enron, sally had four years  experience as a commercial banker and spent seven years as a registered  securities principal with a regional investment banking firm. she also owned  and managed a retail business for several years.  please join me in supporting sally in this additional coordination role for  global risk management operations.\"\"\"\n",
    "wordCounts=defaultdict(int)\n",
    "for word in re.findall(r'[a-z]+', line.lower()):\n",
    "    wordCounts[word] += 1\n",
    "for key in sorted(wordCounts)[0:10]:\n",
    "    print (key, wordCounts[key])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the code block below, then execute the cell as well as the cell below it. \n",
    "#### This will write a file named alice_words.py and run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the output per line should be a tab separated key-value pair with the following format WORD TAB count\n",
    "<pre>\n",
    "a          2333333\n",
    "abide      2\n",
    "able       1\n",
    "about      102\n",
    "above      3\n",
    "absence    1\n",
    "absurd     2\n",
    "accept     1\n",
    "acceptance 1\n",
    "accepted   2\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting alice_words.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile alice_words.py\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "pathToFile = sys.argv[1]\n",
    "wordCounts = defaultdict(int)\n",
    "\n",
    "\n",
    "def hw11(pathToFile):\n",
    "  # takes the path to the file as command line argument\n",
    "  # prints sorted tab separated list of words and counts\n",
    "  # ex) print word,'\\t',count\n",
    "  # returns sorted list of tuples of words and counts: wordList\n",
    "  # ex) wordList = [('a', 690),('abide', 2),...]\n",
    "  \n",
    "  wordList = []\n",
    "\n",
    "  # START STUDENT CODE HW11\n",
    "  \n",
    "\n",
    "  # END STUDENT CODE HW11\n",
    "  \n",
    "  return wordList\n",
    "\n",
    "hw11(pathToFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python alice_words.py 'alicesTExtFilename.txt' > alice_words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretty print top 10 results from alice_words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           Count\n",
      "====================\n",
      "a                690\n",
      "abide              2\n",
      "able               1\n",
      "about            102\n",
      "above              3\n",
      "absence            1\n",
      "absurd             2\n",
      "accept             1\n",
      "acceptance         1\n",
      "accepted           2\n"
     ]
    }
   ],
   "source": [
    "#str.format() is a handy funcion for human friendly pretty printing:\n",
    "#Examples: https://docs.python.org/2/library/string.html#format-examples\n",
    "print '{:15}{}'.format('Word', 'Count')\n",
    "print '='*20\n",
    "\n",
    "with open(\"alice_words.txt\") as f:\n",
    "  idx = 0\n",
    "  for line in f.readlines():\n",
    "    line = line.strip()\n",
    "    word, count = line.split('\\t')\n",
    "    # print the top 10 lines\n",
    "    if idx < 10:\n",
    "      print '{:17}{:3d}'.format(word, int(count))\n",
    "    idx += 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW1.1.1 How many times does the word alice occur in the book?\n",
    "#### HINT: read the file with python, or use subprocess to access the commandline from within the python function\n",
    "#### As before, fill in the code block below, then execute the cell as well as the cell below it. This will write a file named hw111.py and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hw111.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hw111.py\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "word = sys.argv[1]\n",
    "pathToFile = sys.argv[2]\n",
    "\n",
    "def hw111(word,pathToFile):\n",
    "  # takes a word and the path to the file as arguments\n",
    "  # returns the line containing the word and count\n",
    "  \n",
    "  # START STUDENT CODE HW111\n",
    "  \n",
    "  \n",
    "  \n",
    "  # END STUDENT CODE HW111\n",
    "  \n",
    "print hw111(word,pathToFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python hw111.py 'alice' 'alice_words.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW1.2 Command Line Map Reduce Framework  <a name=\"1.2\"></a>\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "For this HW question:\n",
    "* Read through the provided mapreduce shell script (pWordCount.sh) provided below and all of its comments. When you are comfortable with their purpose and function, respond to the remaining homework questions below. \n",
    "* Run all the code blocks.\n",
    "* No need to modify anything in this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pWordCount.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile pWordCount.sh\n",
    "#!/bin/bash\n",
    "## pWordCount.sh\n",
    "## Author: James G. Shanahan\n",
    "## Usage: pWordCount.sh m wordlist testFile.txt\n",
    "## Input:\n",
    "##       m = number of processes (maps), e.g., 4\n",
    "##       word = a word in quotes, e.g., \"alice\"\n",
    "##       inputFile = a text input file\n",
    "##\n",
    "## Instructions: Read this script and its comments closely.\n",
    "##               Do your best to understand the purpose of each command,\n",
    "##               and focus on how arguments are supplied to mapper.py/reducer.py,\n",
    "##               as this will determine how the python scripts take input.\n",
    "\n",
    "###----------------------------------------------------------------------------------------\n",
    "#\n",
    "# For HW1.3:\n",
    "# modify this script to include shuffle/sort/merge phase, \n",
    "# which will collate wordCount records with the same key (i.e., same word)\n",
    "# run: man sort to learn more about the linux sort command\n",
    "#\n",
    "###----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "usage()\n",
    "{\n",
    "    echo ERROR: No arguments supplied\n",
    "    echo\n",
    "    echo To run use\n",
    "    echo \"pWordCount.sh m word inputFile\"\n",
    "    echo Input:\n",
    "    echo \"number of processes/maps, EG, 4\"\n",
    "    echo \"word = a word in quotes, e.g., 'alice'\"\n",
    "    echo \"inputFile = a text input file\"\n",
    "}\n",
    "\n",
    "if [ $# -eq 0 ]\n",
    "  then\n",
    "    usage  \n",
    "    exit 1\n",
    "fi\n",
    "    \n",
    "## collect user input\n",
    "m=$1 ## the number of parallel processes (maps) to run\n",
    "\n",
    "word=$2 ## if set to \"*\", then all words are used\n",
    "\n",
    "## a text file \n",
    "data=$3\n",
    "\n",
    "## 'wc' determines the number of lines in the data\n",
    "## 'perl -pe' regex strips the piped wc output to a number\n",
    "linesindata=`wc -l $data | perl -pe 's/^.*?(\\d+).*?$/$1/'`\n",
    "\n",
    "## determine the lines per chunk for the desired number of processes\n",
    "linesinchunk=`echo \"$linesindata/$m+1\" | bc`\n",
    "\n",
    "## split the original file into chunks by line\n",
    "split -l $linesinchunk $data $data.chunk.\n",
    "\n",
    "## assign python mappers (mapper.py) to the chunks of data\n",
    "## and emit their output to temporary files\n",
    "for datachunk in $data.chunk.*; do\n",
    "    ## feed word list to the python mapper here and redirect STDOUT to a temporary file on disk\n",
    "    ####\n",
    "    ####\n",
    "    ./mapper.py  \"$word\" < $datachunk > $datachunk.counts &\n",
    "    ####\n",
    "    ####\n",
    "done\n",
    "## wait for the mappers to finish their work\n",
    "wait\n",
    "    \n",
    "\n",
    "    \n",
    "## 'ls' makes a list of the temporary count files\n",
    "## 'perl -pe' regex replaces line breaks with spaces\n",
    "countfiles=`\\ls $data.chunk.*.counts | perl -pe 's/\\n/ /'`\n",
    "## feed the list of countfiles to the python reducer and redirect STDOUT to disk\n",
    "####\n",
    "####\n",
    "cat $countfiles | ./reducer.py  > $data.output\n",
    "####\n",
    "####\n",
    "\n",
    "## clean up the data chunks and temporary count files\n",
    "\\rm $data.chunk.*\n",
    "    \n",
    "## display the content of the output file:\n",
    "cat $data.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "## pWordCount.sh\r\n",
      "## Author: James G. Shanahan\r\n",
      "## Usage: pWordCount.sh m wordlist testFile.txt\r\n",
      "## Input:\r\n",
      "##       m = number of processes (maps), e.g., 4\r\n",
      "##       word = a word in quotes, e.g., \"alice\"\r\n",
      "##       inputFile = a text input file\r\n",
      "##\r\n",
      "## Instructions: Read this script and its comments closely.\r\n"
     ]
    }
   ],
   "source": [
    "!head pWordCount.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change the execution priviledges to make the shell script executable by all\n",
    "!chmod a+x pWordCount.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the framework without parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: No arguments supplied\r\n",
      "\r\n",
      "To run use\r\n",
      "pWordCount.sh m wordlist inputFile\r\n",
      "Input:\r\n",
      "number of processes/maps, EG, 4\r\n",
      "word = a space-separated list of words in quotes, e.g., 'alice'\r\n",
      "inputFile = a text input file\r\n"
     ]
    }
   ],
   "source": [
    "! ./pWordCount.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following two cells to generate mapper and reducer files, then run the shell script again with arguments.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/python\n",
    "import sys\n",
    "import re\n",
    "count = 0\n",
    "\n",
    "findword = sys.argv[1]\n",
    "for line in sys.stdin:\n",
    "    # count all occurances of the word in each line:\n",
    "    count = count + line.lower().count(findword)\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    "## Description: reducer code for HW1.2\n",
    "import sys\n",
    "import re\n",
    "sum = 0\n",
    "\n",
    "for line in sys.stdin:\n",
    "  sum += int(line)\n",
    "\n",
    "print sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the files executable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!chmod a+x mapper.py\n",
    "!chmod a+x reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the framework with parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!./pWordCount.sh 4 'alice' 'alicesTExtFilename.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW1.3 WordCount via Command Line Map Reduce Framework  <a name=\"1.3\"></a>\n",
    "[Back to Table of Contents](#TOC)\n",
    "### Dont forget to add a sort component to your MapReduce framework and leverage the sort order in your reduceer (i.e., there will be no need for a sort in reducer.py).\n",
    "Write the mapper.py/reducer.py combination to perform WordCount using the command line mapreduce framework containing an alphabetical listing of all the words, and the number of times each occurs, in the text version of Alice’s Adventures in Wonderland. (You can obtain a free plain text version of the book, along with many others, from [here](http://www.gutenberg.org/cache/epub/11/pg11.txt) The first 10 lines of your output file should look something like this (the counts are not totally precise):\n",
    "\n",
    "To do so, make sure of the following:\n",
    "   \n",
    "* That the mapper.py counts all occurrences of a single word\n",
    "* In the pWordCount.sh, please insert a sort command to collate the output key-value pair records by key from the mappers. E.g., sort -k1,1. Use \"man sort\" to learn more about Unix sorts.\n",
    "* reducer.py sums the count value from the collated records for each  word. There should be no sort in the reducer.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "a          690\n",
    "abide      2\n",
    "able       1\n",
    "about      102\n",
    "above      3\n",
    "absence    1\n",
    "absurd     2\n",
    "accept     1\n",
    "acceptance 1\n",
    "accepted   2\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, mapper.py will read in a portion (i.e., a single record corresponding to a row) of the Alice in Wonderland data,\n",
    "count the number of occurences of the  word in question and print/emit a count to the output stream. The reducer responsible for reading in counts of the word from the input stream, and summarizing them before printing that summary to the output stream.\n",
    "See example the [notebook](http://nbviewer.jupyter.org/urls/dl.dropbox.com/s/5zq0faibmvtjlbr/DivideAndConquer2-python-Plus-CmdLine.ipynb)\n",
    "See video section 1.12.1 1.12.1 Poor Man's MapReduce Using Command Line (Part 2) located at: \n",
    "https://learn.datascience.berkeley.edu/mod/page/view.php?id=10961\n",
    "\n",
    "NOTE in your python notebook create a cell to save your mapper/reducer to disk using magic commands (see example here)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "# START STUDENT CODE HW13MAPPER\n",
    "\n",
    "# END STUDENT CODE HW13MAPPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "# START STUDENT CODE HW13REDUCER\n",
    "\n",
    "# END STUDENT CODE HW13REDUCER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell use the Unix chmod command to change the permissions of the mapper/reducer using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x mapper.py; \n",
    "!chmod +x reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the command below with 4 mappers. You should get the same result as in HW1.1.1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: ./pWordCount.sh: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!./pWordCount.sh 4 '*' 'alicesTExtFilename.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW1.4 - Count words staring with uppercase and words starting with lowercase (This is an OPTIONAL HW) <a name=\"1.4\"></a>\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Change the mapper.py/reducer.py combination so that you get only the number of words starting with an uppercase letter, and the number of words starting with a lowercase letter for Alice in Wonderland available [here](http://www.gutenberg.org/cache/epub/11/pg11.txt). In other words, you need an output file with only 2 lines, one giving you the number of words staring with a lowercase ('a' to 'z'), and the other line indicating the number of words starting with an uppercase letter ('A' to 'Z'). In the pWordCount.sh, please insert a sort command to collate the output key-value pair records by key from the mappers. E.g., sort -k1,1. Use \"man sort\" to learn more about Unix sorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW1.5 Bias-Variance (This is an OPTIONAL HW) <a name=\"1.5\"></a>\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Provide and example of bias variance in action for a similated function y = f(x). E.g., y = sin(x+x^2). Provide code, data, and graphs. \n",
    "\n",
    "Using a bias-variance decomposition analsysis on your choosen problem, describe how you would decide which model to choose when you dont know the true function and how does this choice compare to the choice you made using the true function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](#TOC)\n",
    "<center><div class='jumbotron'><h2 style='color:green'>-------  END OF HOWEWORK --------</h2></div></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
